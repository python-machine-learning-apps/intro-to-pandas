{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ![](https://ga-dash.s3.amazonaws.com/production/assets/logo-9f88ae6c9c3871690e33280fcf557f33.png) \n",
    "# Pandas for Exploratory Data Analysis I \n",
    "by [@josephofiowa](https://twitter.com/josephofiowa) and _updated B Rhodes (DC)_\n",
    "\n",
    "Pandas is the most prominent Python library for exploratory data analysis (EDA). The functions Pandas supports are integral to understanding, formatting, and preparing our data. Formally, we use Pandas to investigate, wrangle, munge, and clean our data. Pandas is the Swiss Army Knife of data manipulation!\n",
    "\n",
    "\n",
    "We'll have two coding-heavy sessions on Pandas. In this one, we'll use Pandas to:\n",
    " - Read in a dataset\n",
    " - Investigate a dataset's integrity\n",
    " - Filter, sort, and manipulate a DataFrame's series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About the Dataset: Adventureworks Cycles\n",
    "\n",
    "<img align=\"right\" src=\"http://lh6.ggpht.com/_XjcDyZkJqHg/TPaaRcaysbI/AAAAAAAAAFo/b1U3q-qbTjY/AdventureWorks%20Logo%5B5%5D.png?imgmax=800\">\n",
    "\n",
    "For today's Pandas exercises, we will be using a dataset developed by Microsoft for training purposes in SQL server, known the [Adventureworks Cycles 2014OLTP Database](https://github.com/Microsoft/sql-server-samples/releases/tag/adventureworks). It is based on a fictitious company called Adventure Works Cycles (AWC), a multinational manufacturer and seller of bicycles and accessories. The company is based in Bothell, Washington, USA and has regional sales offices in several countries. We will be looking at a single table from this database, the Production.Product table, which outlines some of the products this company sells. \n",
    "\n",
    "A full data dictionary can be viewed [here](https://www.sqldatadictionary.com/AdventureWorks2014/).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a closer look at the Production.Product table [data dictionary](https://www.sqldatadictionary.com/AdventureWorks2014/Production.Product.html), which is a description of the fields (columns) in the table (the .csv file we will import below):\n",
    "- **ProductID** - Primary key for Product records.\n",
    "- **Name** - Name of the product.\n",
    "- **ProductNumber** - Unique product identification number.\n",
    "- **MakeFlag** - 0 = Product is purchased, 1 = Product is manufactured in-house.\n",
    "- **FinishedGoodsFlag** - 0 = Product is not a salable item. 1 = Product is salable.\n",
    "- **Color** - Product color.\n",
    "- **SafetyStockLevel** - Minimum inventory quantity.\n",
    "- **ReorderPoint** - Inventory level that triggers a purchase order or work order.\n",
    "- **StandardCost** - Standard cost of the product.\n",
    "- **ListPrice** - Selling price.\n",
    "- **Size** - Product size.\n",
    "- **SizeUnitMeasureCode** - Unit of measure for the Size column.\n",
    "- **WeightUnitMeasureCode** - Unit of measure for the Weight column.\n",
    "- **DaysToManufacture** - Number of days required to manufacture the product.\n",
    "- **ProductLine** - R = Road, M = Mountain, T = Touring, S = Standard\n",
    "- **Class** - H = High, M = Medium, L = Low\n",
    "- **Style** - W = Womens, M = Mens, U = Universal\n",
    "- **ProductSubcategoryID** - Product is a member of this product subcategory. Foreign key to ProductSubCategory.ProductSubCategoryID.\n",
    "- **ProductModelID** - Product is a member of this product model. Foreign key to ProductModel.ProductModelID.\n",
    "- **SellStartDate** - Date the product was available for sale.\n",
    "- **SellEndDate** - Date the product was no longer available for sale.\n",
    "- **DiscontinuedDate** - Date the product was discontinued.\n",
    "- **rowguid** - ROWGUIDCOL number uniquely identifying the record. Used to support a merge replication sample.\n",
    "- **ModifiedDate** - Date and time the record was last updated.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Pandas\n",
    "\n",
    "To [import a library](https://docs.python.org/3/reference/import.html), we write `import` and the library name. For Pandas, is it common to name the library `pd` so that when we reference a function from the Pandas library, we only write `pd` to reference the aliased [namespace](https://docs.python.org/3/tutorial/classes.html#python-scopes-and-namespaces) -- not `pandas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T02:11:51.797999Z",
     "start_time": "2020-11-16T02:11:50.377433Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T02:11:51.811478Z",
     "start_time": "2020-11-16T02:11:51.800846Z"
    }
   },
   "outputs": [],
   "source": [
    "# we can see the details about the imported package by referencing its private class propertys:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in Data\n",
    "\n",
    "Pandas dramatically simplifies the process of reading in data. When we say \"reading in data,\" we mean loading a file into our machine's memory.\n",
    "\n",
    "When you have a CSV, for example, and then you double-click to open it in Microsoft Excel, the open file is \"read into memory.\" You can now manipulate the CSV.\n",
    "\n",
    "When we read data into memory in Python, we are creating an object. We will soon explore this object. _(And, as an aside, when we have a file that is greater than the size of our computer's memory, this is approaching \"Big Data.\")_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we are working with a CSV, we will use the [read CSV](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html) method.<br>A [delimiter](https://en.wikipedia.org/wiki/Delimiter-separated_values) is a character that separates fields (columns) in the imported file. Just because a file says `.csv` does not necessarily mean that a comma is used as the delimiter. In this case, we have a tab character as the delimiter for our columns, so we will be using `sep='\\t'` to tell pandas to 'cut' the columns every time it sees a [tab character in the file](http://vim.wikia.com/wiki/Showing_the_ASCII_value_of_the_current_character)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the url\n",
    "url = 'https://raw.githubusercontent.com/python-machine-learning-apps/intro-to-pandas/main/data/Production.Product.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T02:36:31.256496Z",
     "start_time": "2020-11-16T02:36:31.243419Z"
    }
   },
   "outputs": [],
   "source": [
    "# read the dataset as a DataFrame into a variable named 'prod'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T02:36:31.829047Z",
     "start_time": "2020-11-16T02:36:31.805318Z"
    }
   },
   "outputs": [],
   "source": [
    "# show the head of this dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Documentation Pause*\n",
    "\n",
    "How did we know how to use `pd.read_csv`? Let's take a look at the [documentation](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html). Note the first argument required (`filepath`).\n",
    "> Take a moment to dissect other arguments and options when reading in data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have just created a data structure called a `DataFrame`. See?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T02:36:32.918781Z",
     "start_time": "2020-11-16T02:36:32.911527Z"
    }
   },
   "outputs": [],
   "source": [
    "# show the type of this 'prod' dataset\n",
    "type(prod_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting our DataFrame: The basics\n",
    "\n",
    "We'll now perform basic operations on the DataFrame, denoted with comments.\n",
    "\n",
    "We'll use a few basic commands to quickly size up our data. \n",
    "\n",
    "- `.info()` - gives the number of rows and columns as well as the datatype for each column.\n",
    "- `.describe()` - gives a summary statistics (e.g. mean, count, median and other percentiles)\n",
    "- `.dtypes` - gives the datatypes of each column\n",
    "- `.shape` - gives the number of rows and columns in a dataframe\n",
    "- `.head(n)` & `.tail(n)` - displays the first or last `n` rows of a dataframe.\n",
    "\n",
    "*Note you'll often see commands written as `df.Method()` or `df.Attribute` commands with () are methods or functions. With no parentheses they are attributes. A method does something; it performs some action. An attribute is a value or characterstic. Attributes do not perform any actions. I'll point these out as we go, but remember this difference.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise** display the first 5 rows of the dataset. Type out the command, but before you run it use ```shift-tab``` to view the docstring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T02:36:33.770010Z",
     "start_time": "2020-11-16T02:36:33.740754Z"
    }
   },
   "outputs": [],
   "source": [
    "# Take a quick look to verify the data is what we expect. Display the first 5 rows. \n",
    "# Use the simplest form of the method possible.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T02:36:34.039871Z",
     "start_time": "2020-11-16T02:36:34.022961Z"
    }
   },
   "outputs": [],
   "source": [
    "# last 3 rows - note we can also transpose the display so we aren't horizontally scrolling.\n",
    "# this applies to .head() as well.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Class Question:** \n",
    "- What do you think transpose is doing? Does it change the data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### `.info()`\n",
    "\n",
    "`.info()` provides detailed information on the dataframe. It shows:\n",
    "\n",
    "- number of rows\n",
    "- number of columns\n",
    "- type of Index\n",
    "- datatype of each column\n",
    "- column names\n",
    "- count of non-null values in each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T02:36:34.924806Z",
     "start_time": "2020-11-16T02:36:34.911344Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### `.shape`\n",
    "\n",
    "`.shape` simply gives us the number of rows and columns. It returns a tuple of the form `(row, column).`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T02:36:35.498279Z",
     "start_time": "2020-11-16T02:36:35.493684Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# identify the shape (rows by columns) - the output is a tuple\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have 504 rows, and 25 columns. This is a tuple, so we can extract the parts using indexing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T02:36:36.082091Z",
     "start_time": "2020-11-16T02:36:36.072401Z"
    }
   },
   "outputs": [],
   "source": [
    "# print the number of rows - we can access it just like indexing a list or tuple.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the index\n",
    "An [index](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Index.html) is an immutable ndarray implementing an ordered, sliceable set. It is the basic object storing axis labels for all pandas objects. Think of it as a 'row address' for your data frame (table). It is best practice to explicitly set the index of your dataframe, as these are commonly used as [primary keys](https://en.wikipedia.org/wiki/Primary_key) which can be used to [join](https://www.w3schools.com/sql/sql_join.asp) your dataframe to other dataframes.\n",
    "\n",
    "The dataframe can store different types (int, string, datetime), and when importing data will automatically assign a number to each row, starting at zero and counting up. You can overwrite this, which is what we are going to do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T02:36:36.704910Z",
     "start_time": "2020-11-16T02:36:36.681891Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-25T20:08:33.216210Z",
     "start_time": "2020-09-25T20:08:33.189878Z"
    }
   },
   "source": [
    "We imported the data without specifying an index, so Pandas autogenerated one. In the future you'll see examples where the index is specified explicitly in the data and we can tell Pandas to use that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T02:36:37.312872Z",
     "start_time": "2020-11-16T02:36:37.307483Z"
    }
   },
   "outputs": [],
   "source": [
    "# display the index as imported (auto-generated upon import)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T02:36:37.690432Z",
     "start_time": "2020-11-16T02:36:37.683365Z"
    }
   },
   "outputs": [],
   "source": [
    "# note that our auto-generated index has no name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T02:36:38.220258Z",
     "start_time": "2020-11-16T02:36:38.210629Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Here we are looking at two data columns plus the index;\n",
    "# the one on the left is the index (automatically generated upon import by pandas)\n",
    "# 'ProductID' is our PK (primary key) from our imported table. 'Name' is a data column.\n",
    "# Notice that the generated index starts at zero and our PK starts at 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T02:36:39.146424Z",
     "start_time": "2020-11-16T02:36:39.107261Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T02:36:39.954204Z",
     "start_time": "2020-11-16T02:36:39.944837Z"
    }
   },
   "outputs": [],
   "source": [
    "# Setting the index overwrites the automatically generated index\n",
    "# with our PK, which resided in the 'ProductID' column.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's just look at the Name column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T02:36:41.091218Z",
     "start_time": "2020-11-16T02:36:41.084752Z"
    }
   },
   "outputs": [],
   "source": [
    "# Note how our index property has changed as a result - the values in our index are the ProductID numbers we had originally.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T02:36:41.569386Z",
     "start_time": "2020-11-16T02:36:41.563103Z"
    }
   },
   "outputs": [],
   "source": [
    "# And our index has also inherited the name of our 'ProductID' column\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Column headers and datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T02:36:42.264058Z",
     "start_time": "2020-11-16T02:36:42.238792Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T02:36:42.570467Z",
     "start_time": "2020-11-16T02:36:42.566283Z"
    }
   },
   "outputs": [],
   "source": [
    "# print the columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T02:36:42.901320Z",
     "start_time": "2020-11-16T02:36:42.893707Z"
    }
   },
   "outputs": [],
   "source": [
    "# examine the datatypes of the columns\n",
    "# note that these were automatically inferred by pandas upon import!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T02:36:43.237957Z",
     "start_time": "2020-11-16T02:36:43.234153Z"
    }
   },
   "outputs": [],
   "source": [
    "# Note the output of .dtypes is a Pandas Series.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T02:36:43.557222Z",
     "start_time": "2020-11-16T02:36:43.544620Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# an alternative view as a DataFrame.\n",
    "# Here we use the pd.DataFrame construct to generate a new dataframe.\n",
    "# use the shift-tab trick to see look at the docstring to see how this method works \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Class Question:** \n",
    "Why do datatypes matter? What operations could we perform on some datatypes that we could not on others? Note the importance of this in checking dataset integrity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting a Column\n",
    "\n",
    "We can select columns in two ways. Either we treat the column as an attribute of the DataFrame or we index the DataFrame for a specific element (in this case, the element is a column name)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T02:36:44.505802Z",
     "start_time": "2020-11-16T02:36:44.484274Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T02:36:44.796877Z",
     "start_time": "2020-11-16T02:36:44.789816Z"
    }
   },
   "outputs": [],
   "source": [
    "# Select a single column to display will output a Pandas Series.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also reference a specific column using dot notation in the form `df.ColumnName`. Or in our example:\n",
    "- `prod_df.Name` will display the column as a Pandas Series.\n",
    "\n",
    "**HINT:** I don't recommend the dot construct `df.ColumnName` because there are cases where it will not work.\n",
    "\n",
    "**Question**: Under what circumstances might this format not work?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T02:36:45.455522Z",
     "start_time": "2020-11-16T02:36:45.447948Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T02:36:45.757543Z",
     "start_time": "2020-11-16T02:36:45.747379Z"
    }
   },
   "outputs": [],
   "source": [
    "# We can also reference a specific column with \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T02:36:46.025932Z",
     "start_time": "2020-11-16T02:36:46.010586Z"
    }
   },
   "outputs": [],
   "source": [
    "# Using double brackets will output a Pandas Dataframe\n",
    "# Note: to output more than one column you always must use double brackets. See below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T02:36:46.262966Z",
     "start_time": "2020-11-16T02:36:46.248046Z"
    }
   },
   "outputs": [],
   "source": [
    "# Use double brackets to show two or more columns in a dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T02:36:46.472838Z",
     "start_time": "2020-11-16T02:36:46.467884Z"
    }
   },
   "outputs": [],
   "source": [
    "# show the difference in data types by using single and double square brackets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T02:36:46.771759Z",
     "start_time": "2020-11-16T02:36:46.762588Z"
    }
   },
   "outputs": [],
   "source": [
    "# Often it's easier to define a list with the column names you want to use.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T02:36:47.039933Z",
     "start_time": "2020-11-16T02:36:47.028889Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Renaming Columns\n",
    "\n",
    "Perhaps we want to rename our columns. There are a few options for doing this.\n",
    "\n",
    "Rename the columns all the columns or a subset of columns using either a list-based approach or a dictionary based approach.\n",
    "\n",
    "Here we use a list to rename all the columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the `pd.DataFrame.columns` property can be cast to a `list` type. Originally, it's a `pd.core.indexes.base.Index` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T02:36:48.425554Z",
     "start_time": "2020-11-16T02:36:48.419154Z"
    }
   },
   "outputs": [],
   "source": [
    "# create a new dataframe for demonstration purposes and look at the column names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T02:36:48.837633Z",
     "start_time": "2020-11-16T02:36:48.827484Z"
    }
   },
   "outputs": [],
   "source": [
    "# rename the columns to be lower case \n",
    "# this is a common use case for list comprehensions - changing column names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T02:36:49.221062Z",
     "start_time": "2020-11-16T02:36:49.206046Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can explicitly cast these to a list object as such, by using the built-in `list()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T02:36:50.039613Z",
     "start_time": "2020-11-16T02:36:50.031954Z"
    }
   },
   "outputs": [],
   "source": [
    "# Note that .columns are not list objects\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use the list approach to rename some, but not all the columns. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T02:36:50.768338Z",
     "start_time": "2020-11-16T02:36:50.759536Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also rename **specific** columns by using a dictionary and the `.rename()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T02:36:51.639482Z",
     "start_time": "2020-11-16T02:36:51.610552Z"
    }
   },
   "outputs": [],
   "source": [
    "# rename one or more columns with a dictionary. Note: inplace=False will return a new dataframe,\n",
    "# but leave the original dataframe untouched. Change this to True to modify the original dataframe.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common Column Operations\n",
    "\n",
    "While this is non-comprehensive, these are a few key column-specific data checks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Descriptive statistics:**  the minimum, first quartile, median, third quartile, and maximum.\n",
    "\n",
    "(And more! The mean too.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Five Number Summary (all assumes numeric data):\n",
    "- **Min:** The smallest value in the column\n",
    "- **Max:** The largest value in the column\n",
    "- **Quartile:** A quartile is one fourth of our data\n",
    "    - **First quartile:** This is the bottom most 25 percent\n",
    "    - **Median:** The middle value. (Line all values biggest to smallest - median is the middle!) Also the 50th percentile\n",
    "    - **Third quartile:** This the the top 75 percentile of our data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://www.mathsisfun.com/data/images/quartiles-a.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T02:36:53.724794Z",
     "start_time": "2020-11-16T02:36:53.680730Z"
    }
   },
   "outputs": [],
   "source": [
    "# note - .describe() *default* only checks numeric datatypes\n",
    "# It will ignore non-numerical data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T02:36:56.391601Z",
     "start_time": "2020-11-16T02:36:56.334280Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# add a .T to display the transpose of the result. It's often easier to read.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T02:37:00.511944Z",
     "start_time": "2020-11-16T02:37:00.488743Z"
    }
   },
   "outputs": [],
   "source": [
    "# Quick Exercise:\n",
    "# show .describe() for the 'MakeFlag', 'SafetyStockLevel', 'StandardCost' fields.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Value Counts:** `pd.Series.value_counts()` count the occurrence of each value within our series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T02:37:01.851492Z",
     "start_time": "2020-11-16T02:37:01.844176Z"
    }
   },
   "outputs": [],
   "source": [
    "# show the most popular product colors (aggregated by count, descending by default)\n",
    "# we use the .value_counts() method \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T02:37:02.379265Z",
     "start_time": "2020-11-16T02:37:02.373022Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Unique values:** Determine the number of distinct values within a given series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T02:37:04.106988Z",
     "start_time": "2020-11-16T02:37:04.100663Z"
    }
   },
   "outputs": [],
   "source": [
    "# What are the unique colors for the products?\n",
    "# the method returns the unique values, but not the count of each\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T02:37:05.832004Z",
     "start_time": "2020-11-16T02:37:05.825114Z"
    }
   },
   "outputs": [],
   "source": [
    "# the attribute gives reference to the method. \n",
    "# You want to be careful that you are using the method, so be sure you include the ().\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T02:37:06.630564Z",
     "start_time": "2020-11-16T02:37:06.624747Z"
    }
   },
   "outputs": [],
   "source": [
    "# how many distinct colors are there?\n",
    "# .nunique by default doesn't count NaN or null values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T02:37:07.791357Z",
     "start_time": "2020-11-16T02:37:07.785395Z"
    }
   },
   "outputs": [],
   "source": [
    "# We can also include nulls with .nunique() as such:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering on a Single Condition\n",
    "\n",
    "Filtering and sorting are key processes that allow us to drill into the details and cross sections of our dataset.\n",
    "\n",
    "One approach to filtering, or selecting subsets of our data, is to use a process called **Boolean Indexing** or **Boolean Filtering**. This is where we define a Boolean condition, and use that Boolean index into our DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall: our given dataset has a column `Color`. Let's see if we can find all products that are `Black`. Let's take a look at the first 10 rows of the dataframe to see how it looks as-is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T02:37:09.405560Z",
     "start_time": "2020-11-16T02:37:09.397220Z"
    }
   },
   "outputs": [],
   "source": [
    "# show the first 10 rows of the 'Color' column\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By applying a `boolean mask` to this dataframe, `== 'Black'`, we can get the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T02:37:10.427356Z",
     "start_time": "2020-11-16T02:37:10.420829Z"
    }
   },
   "outputs": [],
   "source": [
    "# set the previous output to == Black\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use that 'mask' from above, and apply it to our full dataframe. Every time we have a `True` in a row, we return the row. If we have a `False` in that row, we do not return it. The result is a dataframe that only has rows where `Color` is `Black`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T02:37:11.976084Z",
     "start_time": "2020-11-16T02:37:11.946777Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# show the full prod DataFrame where Color is Black\n",
    "# Note I prefer the approach of assigning the boolean condition to a variable and using that variable\n",
    "# to reference the dataframe. It makes the code easier to read, especially if you have multiple conditions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T02:37:12.748699Z",
     "start_time": "2020-11-16T02:37:12.741477Z"
    }
   },
   "outputs": [],
   "source": [
    "# We can see the resulting dataframe has a shape (93,24)\n",
    "# This corresponds to the 93 items colored Black we found above with .value_counts().\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's calculate the **average ListPrice** for the **salable products**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Think: What are the component parts of this problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T02:37:14.492969Z",
     "start_time": "2020-11-16T02:37:14.465892Z"
    }
   },
   "outputs": [],
   "source": [
    "# First, we need to get salable items. \n",
    "# Use your data dictionary from the beginning of this lesson.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need to find average list price of those above items. Let's just get the 'ListPrice' column for starters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T02:37:15.898986Z",
     "start_time": "2020-11-16T02:37:15.890819Z"
    }
   },
   "outputs": [],
   "source": [
    "# note the"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the average of that column, just take `.mean()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T02:37:17.092077Z",
     "start_time": "2020-11-16T02:37:17.087153Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can take a shortcut and just use `.describe()` here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T02:37:18.193727Z",
     "start_time": "2020-11-16T02:37:18.179778Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sneak peek**: Another handy trick is to use `.hist()` to get a distribution of a continuous variable - in this case, `ListPrice`. We'll cover this visualization more in future lessons:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T02:37:19.660758Z",
     "start_time": "2020-11-16T02:37:19.420522Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering on Multiple Conditions\n",
    "\n",
    "Here, we will filter on _multiple conditions_. Before, we filtered on rows where Color was Black. We also filtered where FinishedGoodsFlag was equal to 1. Let's see what happens when we filter on *both* simultaneously. \n",
    "\n",
    "The format for multiple conditions is:\n",
    "\n",
    "`df[ (df['col1'] == value1) & (df['col2'] == value2) ]`\n",
    "\n",
    "Or, more simply:\n",
    "\n",
    "`df[ (CONDITION 1) & (CONDITION 2) ]`\n",
    "\n",
    "Which eventually may evaluate to something like:\n",
    "\n",
    "`df[ True & False ]`\n",
    "\n",
    "...on a row-by-row basis. If the end result is `False`, the row is omitted.\n",
    "\n",
    "_Don't forget parentheses in your conditions!_ This is a common mistake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T02:37:20.605126Z",
     "start_time": "2020-11-16T02:37:20.577122Z"
    }
   },
   "outputs": [],
   "source": [
    "# Let's look at a table where Color is Black, AND FinishedGoodsFlag is 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T02:37:20.941397Z",
     "start_time": "2020-11-16T02:37:20.915183Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T02:37:21.350787Z",
     "start_time": "2020-11-16T02:37:21.343187Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T02:37:21.796327Z",
     "start_time": "2020-11-16T02:37:21.779737Z"
    }
   },
   "outputs": [],
   "source": [
    "# Here we have an example of a list price of greater than 50, \n",
    "# OR a product size that is not equal to 'XL'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting\n",
    "\n",
    "We can sort the entire DataFrame based on one column in the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T02:37:22.840444Z",
     "start_time": "2020-11-16T02:37:22.808987Z"
    }
   },
   "outputs": [],
   "source": [
    "# let's sort by standard cost, descending"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This one is a little more advanced, but it demonstrates a few things:\n",
    "- Conversion of a `numpy.ndarray` object (return type of `pd.Series.unique()`) into a `pd.Series` object\n",
    "- `pd.Series.sort_values` with the `by=` kwarg omitted (if only one column is the operand, `by=` doesn't need specified\n",
    "- Alphabetical sort of a string field, `ascending=True` means A->Z\n",
    "- Inclusion of nulls, `NaN` in a string field (versus omission with a float/int as prior example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T02:37:23.867047Z",
     "start_time": "2020-11-16T02:37:23.860075Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Independent Exercises\n",
    "\n",
    "Do your best to complete the following prompts. Don't hesitate to look at code we covered above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the first 4 rows of the whole DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T02:37:25.530754Z",
     "start_time": "2020-11-16T02:37:25.527698Z"
    }
   },
   "outputs": [],
   "source": [
    "# your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many rows are in the dataframe? Return the answer as an int."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many columns? Return the answer as an int."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many different product lines are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the values of these product lines?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the number of values for the product lines match the number you have using `.nunique()`? Why or why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take the output from your previous answer (using `.unique()`). Select the label corresponding to the `Road` product line using list indexing notation. How many characters are in this string?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do you notice anything odd about this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many products are there for the `Road` product line? Don't forget what you just worked on above! Return your answer as an int."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many products are there in the `Women's Mountain` category? Return your answer as an int. _Hint: Use the data dictionary above!_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Challenge:** What are the top 3 _most expensive list price_ product that are either in the `Women's` `Mountain` category, _OR_ `Silver` in `Color`? Return your answer as a DataFrame object, with the `ProductID` index, `NewName` relabeled as `Name`, and `ListPrice` columns. Perform the statement in one execution, and do not mutate the source DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recap\n",
    "\n",
    "We covered a lot of ground! It's ok if this takes a while to gel.\n",
    "\n",
    "```python\n",
    "\n",
    "# basic DataFrame operations\n",
    "df.head()\n",
    "df.tail()\n",
    "df.shape\n",
    "df.columns\n",
    "df.Index\n",
    "\n",
    "# selecting columns\n",
    "df.column_name\n",
    "df['column_name']\n",
    "\n",
    "# renaming columns\n",
    "df.rename({'old_name':'new_name'}, inplace=True)\n",
    "df.columns = ['new_column_a', 'new_column_b']\n",
    "\n",
    "# notable columns operations\n",
    "df.describe() # five number summary\n",
    "df['col1'].nunique() # number of unique values\n",
    "df['col1'].value_counts() # number of occurrences of each value in column\n",
    "\n",
    "# filtering\n",
    "df[ df['col1'] < 50 ] # filter column to be less than 50\n",
    "df[ (df['col1'] == value1) & (df['col2'] > value2) ] # filter column where col1 is equal to value1 AND col2 is greater to value 2\n",
    "\n",
    "# sorting\n",
    "df.sort_values(by='column_name', ascending = False) # sort biggest to smallest\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "It's common to refer back to your own code *all the time.* Don't hesistate to reference this guide! 🐼\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
